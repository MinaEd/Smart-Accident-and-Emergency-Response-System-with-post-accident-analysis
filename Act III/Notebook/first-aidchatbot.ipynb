{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T00:28:28.216923Z",
     "iopub.status.busy": "2025-03-25T00:28:28.216682Z",
     "iopub.status.idle": "2025-03-25T00:28:35.240538Z",
     "shell.execute_reply": "2025-03-25T00:28:35.239700Z",
     "shell.execute_reply.started": "2025-03-25T00:28:28.216901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install faiss-gpu\n",
    "!pip install googletrans\n",
    "!pip install SpeechRecognition\n",
    "!pip install sentence-transformers googletrans==4.0.0-rc1 openai gtts\n",
    "!pip install deep-translator\n",
    "!pip install langdetect\n",
    "!pip install google-generativeai\n",
    "!pip install genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from deep_translator import GoogleTranslator\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Audio\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing & Model initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T00:32:16.268264Z",
     "iopub.status.busy": "2025-03-25T00:32:16.267939Z",
     "iopub.status.idle": "2025-03-25T00:34:17.599179Z",
     "shell.execute_reply": "2025-03-25T00:34:17.598487Z",
     "shell.execute_reply.started": "2025-03-25T00:32:16.268238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"YOUR_API_TOKEN\")\n",
    "login(token=\"YOUR_API_TOKEN\")\n",
    "\n",
    "with open(\"/kaggle/input/q-and-a-json/Q-and-A-organized-file.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    qa_data = json.load(file)\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "for category in qa_data[\"first_aid_questions\"]:\n",
    "    for item in category[\"questions\"]:\n",
    "        questions.append(item[\"question\"])\n",
    "        answers.append(item[\"answer\"])\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Efficient model\n",
    "\n",
    "question_embeddings = np.array(embedding_model.encode(questions)).astype(\"float32\")\n",
    "index = faiss.IndexFlatL2(question_embeddings.shape[1])\n",
    "index.add(question_embeddings)\n",
    "\n",
    "mistral_model = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "qa_pipeline = pipeline(\"text-generation\", model=mistral_model, tokenizer=mistral_model, torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting audio Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-25T00:46:01.986671Z",
     "iopub.status.busy": "2025-03-25T00:46:01.986363Z",
     "iopub.status.idle": "2025-03-25T00:46:02.296545Z",
     "shell.execute_reply": "2025-03-25T00:46:02.295715Z",
     "shell.execute_reply.started": "2025-03-25T00:46:01.986648Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!ffmpeg -i /kaggle/input/voice-test-chatbot/burn-ar.wav -acodec pcm_s16le -ar 16000 burn_ar_fixed.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions & Main Chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-25T15:17:10.513968Z",
     "iopub.status.idle": "2025-03-25T15:17:10.514307Z",
     "shell.execute_reply": "2025-03-25T15:17:10.514156Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def paraphrase_to_egyptian(text):\n",
    "    \"\"\" Convert Modern Standard Arabic (MSA) to Egyptian Arabic (العامية المصرية) \"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")  \n",
    "    prompt = f\"Rewrite this text in simple Egyptian Arabic dialect (العامية المصرية) using common everyday terms. Provide only ONE clear version without alternatives: {text}\"\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "    ########################################################################################\n",
    "def translate_text(text, src=\"ar\", dest=\"en\"):\n",
    "    return GoogleTranslator(source=src, target=dest).translate(text)\n",
    "    #########################################################################################\n",
    "def find_top_k_answers(query, k=5, threshold=0.9):\n",
    "    query_embedding = np.array(embedding_model.encode([query])).astype(\"float32\")\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    print(distances)\n",
    "    min_distance = min(distances[0]) if distances[0].size > 0 else float(\"inf\")\n",
    "    if min_distance > threshold: \n",
    "        return None \n",
    "    return [(questions[i], answers[i]) for i in indices[0] if i < len(answers)]\n",
    "    ###########################################################################################\n",
    "def refine_with_mistral(prompt, max_new_tokens=100, temperature=0.5, do_sample=False, top_k=30, top_p=0.8):\n",
    "    refined_text = qa_pipeline(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p\n",
    "    )[0][\"generated_text\"]\n",
    "    return refined_text\n",
    "    ##############################################################################################\n",
    "def text_to_speech(text, lang=\"ar\"):\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    tts.save(\"response_burn_ar.mp3\")\n",
    "    return Audio(\"response_burn_ar.mp3\")  \n",
    "    #############################################################################################\n",
    "def chatbot(text):\n",
    "    lang = detect(text)\n",
    "    print(lang)\n",
    "    response = \"\"\n",
    "    if (lang=='ar'):\n",
    "        english_text = translate_text(text, src=\"ar\", dest=\"en\") \n",
    "        top_answers = find_top_k_answers(english_text, k=2)  \n",
    "        if top_answers is None:\n",
    "            return \"معلش مش فاهم السؤال !\" \n",
    "        answer_prompt = \"Refine this answer in Arabic: \" + \" \".join([ans for _, ans in top_answers])\n",
    "        refined_answer = refine_with_mistral(answer_prompt)\n",
    "        standard_arabic = translate_text(refined_answer, src=\"en\", dest=\"ar\")\n",
    "        response = paraphrase_to_egyptian(standard_arabic)\n",
    "        \n",
    "    elif(lang=='en') :\n",
    "        top_answers = find_top_k_answers(text, k=2)  \n",
    "        if top_answers is None:\n",
    "            return \"Sorry, I don't understand\"  \n",
    "        answer_prompt = \"Refine this answer in English: \" + \" \".join([ans for _, ans in top_answers])\n",
    "        refined_answer = refine_with_mistral(answer_prompt)\n",
    "        response=refined_answer.replace(\"Refine this answer in English: \", \"\")\n",
    "    return response\n",
    "       ##########################################################################################\n",
    "def voice_chatbot():\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio_file = \"/kaggle/working/burn_ar_fixed.wav\" \n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    detected_lang = None  \n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio, language=\"ar\")\n",
    "        detected_lang = \"ar\"\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Arabic recognition failed, trying English...\")\n",
    "    if detected_lang is None:\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio, language=\"en\")\n",
    "            detected_lang = \"en\"\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Error: Could not understand the audio in English or Arabic.\")\n",
    "            return\n",
    "    \n",
    "    print(f\"Recognized Text: {text} (Detected: {detected_lang})\")\n",
    "    response = chatbot(text)\n",
    "    return text_to_speech(response, lang=detected_lang)\n",
    "    ###########################################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        mode = input(\"Choose mode: (1) Text, (2) Voice, (3) Exit: \")\n",
    "        if mode == \"1\":\n",
    "            user_input = input(\"You: \")\n",
    "            print(chatbot(user_input))\n",
    "        elif mode == \"2\":\n",
    "            voice_chatbot()\n",
    "        elif mode == \"3\":\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid option. Try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6816036,
     "sourceId": 10956357,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6957831,
     "sourceId": 11152718,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
